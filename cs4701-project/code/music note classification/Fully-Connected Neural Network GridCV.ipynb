{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layered Perceptron via Grid Search CV (ft. Adam vs LBFGS) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1618274218296,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "ZU3LaV45oeI1"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28 x 28 images ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default: Adam Optimizer #### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default 'adam' solver, according to the scikit-learn documentation for MLPClassifier, \"works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1618274362072,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "xu4UtD9GotNW"
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "data_small = pandas.read_csv('data28.csv')\n",
    "y = data_small['label']\n",
    "X = data_small[data_small.columns[1:]]\n",
    "\n",
    "# 80-20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1618274476519,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "A9Jz4ymUo2J_"
   },
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "indices_to_keep=~X_train.isin([np.nan,np.inf,-np.inf]).any(1)\n",
    "\n",
    "X_train=X_train[indices_to_keep]\n",
    "y_train=y_train[indices_to_keep]\n",
    "\n",
    "indices_to_keep_test=~X_test.isin([np.nan,np.inf,-np.inf]).any(1)\n",
    "\n",
    "X_test=X_test[indices_to_keep_test]\n",
    "y_test=y_test[indices_to_keep_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a full grid search with the parameters specified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1618274531199,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "Hg2yC3qbovk_"
   },
   "outputs": [],
   "source": [
    "#Neural Network to generate predictions\n",
    "def predNN_2(X_train, y_train, im_size = 28):\n",
    "    clf = GridSearchCV(estimator=MLPClassifier(max_iter=50000),\n",
    "          param_grid={'early_stopping' : [True, False],\n",
    "                      'hidden_layer_sizes': [100, 200, 300, 400, 500],\n",
    "                      'activation': ['relu', 'tanh', 'logistic'],\n",
    "                      'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "                      'learning_rate_init': [.0001, .001, .01, .1]},\n",
    "                      n_jobs = -1, verbose = 4)\n",
    "    \n",
    "    # Note (put in report): we picked the default 'adam' solver since, according to the scikit-learn documentation for MLPClassifier, \n",
    "    # it \"works pretty well on relatively large datasets (with thousands of training samples or more) \n",
    "    # in terms of both training time and validation score.\" Note that 'lgbfs' is very slow!!\n",
    "    \n",
    "    # Note: GridSearchCV by default performs 5-fold CV. \n",
    "    \n",
    "    print(\"Fitting\")\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print('Grid search CV time for', im_size, 'x', im_size, 'images took', t1 - t0, 'seconds')\n",
    "    print(\"Optimized parameters:\", clf.best_params_)\n",
    "    print(\"Weighted validation score:\", clf.best_score_)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3383536,
     "status": "ok",
     "timestamp": 1618277929036,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "EoaPtCGNozj0",
    "outputId": "17084d71-3b6e-4baa-d1bf-39bca26724d8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "Grid search CV time for 28 x 28 images took 6134.6064739227295 seconds\n",
      "Optimized parameters: {'activation': 'logistic', 'early_stopping': False, 'hidden_layer_sizes': 400, 'learning_rate': 'constant', 'learning_rate_init': 0.0001}\n",
      "Weighted validation score: 0.8779999999999999\n"
     ]
    }
   ],
   "source": [
    "#Calling Neural Network for Predictions\n",
    "\n",
    "classifier = predNN_2(X_train, y_train, 28)\n",
    "preds = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cv results (such as mean fit times for each hyperparam configuration) to file\n",
    "with open('fcnn_gridcv_28_adam.txt', 'w') as file:\n",
    "    file.write(str(classifier.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time time for 28 x 28 images took 37.561065912246704 seconds\n"
     ]
    }
   ],
   "source": [
    "activation = classifier.best_params_['activation']\n",
    "hidden_layer_sizes = classifier.best_params_['hidden_layer_sizes']\n",
    "learning_rate = classifier.best_params_['learning_rate']\n",
    "learning_rate_init = classifier.best_params_['learning_rate_init']\n",
    "early_stopping = classifier.best_params_['early_stopping']\n",
    "\n",
    "classifier = MLPClassifier(early_stopping=early_stopping, activation=activation, hidden_layer_sizes=hidden_layer_sizes, max_iter=50000, learning_rate=learning_rate, learning_rate_init=learning_rate_init)\n",
    "t0 = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print('Training time time for', 28, 'x', 28, 'images took', t1 - t0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1618278143453,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "K3PsZopPo6qW",
    "outputId": "f8d8636b-c25f-4516-dd1d-4e24cef6f146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92225"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "train_accNN = accuracy_score(y_train, classifier.predict(X_train)) \n",
    "train_accNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1618278161854,
     "user": {
      "displayName": "Casey Justus",
      "photoUrl": "",
      "userId": "06906745805334060521"
     },
     "user_tz": 240
    },
    "id": "FnlDbtlQo7PO",
    "outputId": "e336350b-3624-4422-ef32-acb885965bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test accuracy\n",
    "test_accNN = accuracy_score(y_test, classifier.predict(X_test)) \n",
    "test_accNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detour: LBFGS Optimizer (DO NOT RUN!!!) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the LBFGS solver will take significantly longer, as it \"converges faster and performs better\" for small datasets, according to the documentation. \n",
    "\n",
    "We want to explore the following: how much does using the LBFGS solver affect the final test accuracy? \n",
    "\n",
    "LBFGS: Limited-memory Broyden–Fletcher–Goldfarb–Shanno. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "data_small = pandas.read_csv('data28.csv')\n",
    "y = data_small['label']\n",
    "X = data_small[data_small.columns[1:]]\n",
    "\n",
    "# 70-30 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "indices_to_keep=~X_train.isin([np.nan,np.inf,-np.inf]).any(1)\n",
    "\n",
    "X_train=X_train[indices_to_keep]\n",
    "y_train=y_train[indices_to_keep]\n",
    "\n",
    "indices_to_keep_test=~X_test.isin([np.nan,np.inf,-np.inf]).any(1)\n",
    "\n",
    "X_test=X_test[indices_to_keep_test]\n",
    "y_test=y_test[indices_to_keep_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network to generate predictions\n",
    "def predNN_3(X_train, y_train, im_size = 28):\n",
    "    clf = GridSearchCV(estimator=MLPClassifier(solver='lbfgs', max_iter=50000),\n",
    "          param_grid={'early_stopping' : [True, False],\n",
    "                      'hidden_layer_sizes': [100, 200, 300, 400, 500],\n",
    "                      'activation': ['relu', 'tanh', 'logistic'],\n",
    "                      'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "                      'learning_rate_init': [.0001, .001, .01, .1]}, n_jobs=-1,verbose=4)\n",
    "    \n",
    "    # Pick 20 sample configurations to perform CV on. \n",
    "    \n",
    "    print(\"Fitting\")\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print('Grid search CV time for', im_size, 'x', im_size, 'images via LBFGS took', t1 - t0, 'seconds')\n",
    "    print(\"Optimized parameters:\", clf.best_params_)\n",
    "    print(\"Weighted validation score:\", clf.best_score_)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Calling Neural Network for Predictions\n",
    "\n",
    "classifier = predNN_3(X_train, y_train, 28)\n",
    "preds = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cv results (such as mean fit times for each hyperparam configuration) to file\n",
    "with open('fcnn_gridcv_28_lbfgs.txt', 'w') as file:\n",
    "    file.write(str(classifier.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = classifier.best_params_['activation']\n",
    "hidden_layer_sizes = classifier.best_params_['hidden_layer_sizes']\n",
    "\n",
    "classifier = MLPClassifier(early_stopping=early_stopping, activation=activation, hidden_layer_sizes=hidden_layer_sizes, max_iter=50000, learning_rate=learning_rate, learning_rate_init=learning_rate_init)\n",
    "t0 = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print('Training time time for', 28, 'x', 28, 'images took', t1 - t0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy\n",
    "train_accNN = accuracy_score(y_train, classifier.predict(X_train)) \n",
    "train_accNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy\n",
    "test_accNN = accuracy_score(y_test, classifier.predict(X_test)) \n",
    "test_accNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above grid search CV for 11 hours, and having observed that it's barely halfway finished, we can conclude that the LBFGS is infeasible for our 5000-example large dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 x 64 images ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Adam optimizer for computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "data_large = pandas.read_csv('data64.csv')\n",
    "y = data_large['label']\n",
    "\n",
    "X = data_large[data_large.columns[1:]]\n",
    "\n",
    "# 70-30 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "indices_to_keep=~X_train.isin([np.nan,np.inf,-np.inf]).any(1)\n",
    "\n",
    "X_train=X_train[indices_to_keep]\n",
    "y_train=y_train[indices_to_keep]\n",
    "\n",
    "indices_to_keep_test=~X_test.isin([np.nan,np.inf,-np.inf]).any(1)\n",
    "\n",
    "X_test=X_test[indices_to_keep_test]\n",
    "y_test=y_test[indices_to_keep_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "Grid search CV time for 64 x 64 images took 25156.27631998062 seconds\n",
      "Optimized parameters: {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': 500, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001}\n",
      "Weighted validation score: 0.79775\n"
     ]
    }
   ],
   "source": [
    "#Calling Neural Network for Predictions\n",
    "\n",
    "classifier = predNN_2(X_train, y_train, 64)\n",
    "preds = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cv results (such as mean fit times for each hyperparam configuration) to file\n",
    "with open('fcnn_gridcv_64_adam.txt', 'w') as file:\n",
    "    file.write(str(classifier.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time time for 64 x 64 images took 78.14718914031982 seconds\n"
     ]
    }
   ],
   "source": [
    "activation = classifier.best_params_['activation']\n",
    "hidden_layer_sizes = classifier.best_params_['hidden_layer_sizes']\n",
    "learning_rate = classifier.best_params_['learning_rate']\n",
    "learning_rate_init = classifier.best_params_['learning_rate_init']\n",
    "early_stopping = classifier.best_params_['early_stopping']\n",
    "\n",
    "classifier = MLPClassifier(early_stopping=early_stopping, activation=activation, hidden_layer_sizes=hidden_layer_sizes, max_iter=50000, learning_rate=learning_rate, learning_rate_init=learning_rate_init)\n",
    "t0 = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print('Training time time for', 64, 'x', 64, 'images took', t1 - t0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8815"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "train_accNN = accuracy_score(y_train, classifier.predict(X_train)) \n",
    "train_accNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test accuracy\n",
    "test_accNN = accuracy_score(y_test, classifier.predict(X_test)) \n",
    "test_accNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We did not use the LBFGS solver for 64 x 64 images due to its expensive computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAmzgoU9lZpwplAuHDHGWy",
   "name": "Neural Network 4780.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
